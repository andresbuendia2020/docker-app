# -*- coding: utf-8 -*-
"""sateltal_Images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gucKdfeacw42WX62GFn-b-yYikzpQL7h

#**Conjunto de Datos de Predicción de Incendios Forestales (Imágenes Satelitales)**

#**Introducción**

Los incendios forestales representan una amenaza significativa para el medio ambiente, la vida silvestre y las comunidades humanas en todo el mundo. La detección temprana y la predicción precisa de la propagación de los incendios son cruciales para mitigar su impacto. Los datos satelitales proporcionan una herramienta invaluable para monitorear y predecir la actividad de los incendios forestales a gran escala.

El objetivo de este conjunto de datos es facilitar la investigación en la predicción de incendios forestales mediante el análisis de imágenes satelitales. Al identificar patrones y características asociadas con áreas propensas a incendios, se pueden desarrollar modelos predictivos que ayuden en la prevención y el control de incendios forestales.

#**Descripción del Conjunto de Datos**

Este conjunto de datos contiene imágenes satelitales etiquetadas de áreas forestales, con anotaciones que indican la presencia o ausencia de incendios. Cada imagen está asociada con una etiqueta binaria que indica si hay un incendio presente (1) o no (0).

#**Características**

- Archivos de Imágenes: Cada imagen se proporciona en un formato estándar compatible con datos satelitales (por ejemplo, GeoTIFF).
- Objetivo: Presencia de Incendios: Etiqueta binaria que indica si hay un incendio presente (1) o ausente (0) en el área forestal representada en la imagen satelital.

#**Objetivo**

El objetivo principal de este conjunto de datos es permitir el desarrollo y la evaluación de modelos de predicción de incendios forestales basados en imágenes satelitales. Al entrenar y probar diversos algoritmos con este conjunto de datos, los investigadores pueden evaluar el rendimiento de los modelos en la detección y predicción de incendios forestales.

#**Aplicaciones Potenciales**

- Prevención y Respuesta a Incendios: Los modelos basados en este conjunto de datos pueden utilizarse para detectar incendios forestales en etapas tempranas y facilitar una respuesta rápida y efectiva para su control.
- Planificación de Manejo Forestal: La capacidad de predecir la actividad de incendios forestales puede informar sobre estrategias de gestión forestal y ayudar a minimizar el riesgo de incendios catastróficos.
- Protección Ambiental: La detección y prevención de incendios forestales contribuyen a la conservación de ecosistemas naturales y la protección de la biodiversidad.
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/drive')

ruta_archivo = '/content/drive/My Drive/kaggle.json'

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d abdelghaniaaba/wildfire-prediction-dataset

!unzip wildfire-prediction-dataset.zip

# Commented out IPython magic to ensure Python compatibility.
from mpl_toolkits.mplot3d import Axes3D
from sklearn.preprocessing import StandardScaler
from keras.preprocessing import image
import numpy as np
import PIL
import pandas as pd
from imgaug import augmenters, imgaug
from skimage.transform import rescale
from scipy import ndimage
from skimage import io, data,color
from skimage.io import imread
from skimage.transform import resize, rescale, downscale_local_mean
from skimage.filters import roberts, sobel, scharr, prewitt
from skimage.feature import canny
from skimage.filters.rank import entropy
from skimage.morphology import disk
import cv2
import os
import keras
import tensorflow as tf
from tensorflow import keras
from keras.models import Model, Sequential, load_model
from keras.utils import image_dataset_from_directory
from keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.optimizers import Adam, Adagrad
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

import seaborn as sns
plt.style.use('fivethirtyeight')
import pickle


# %matplotlib inline

"""#**PREPROCESAMOS LA DATA DIMENSIONANDO LAS RADIOGRAFIAS**

"""

labels = ['nowildfire', 'wildfire']
img_size = 200
def get_training_data(data_dir):
    data = []
    for label in labels:
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
                resized_arr = cv2.resize(img_arr, (img_size, img_size))
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)
    return np.array(data)

"""DIVIMOS LA DATA EN TRAIN, TEST Y VALIDACION."""

train = "../content/train"
test  = "../content/test"
valid  = "../content/valid"

"""#**IMAGENES**

mostramos una imagen normal
"""

plt.figure(figsize=(8,6))
img = plt.imread('../content/train/nowildfire/-113.917243,51.101323.jpg')
display(img)
print("\n")
display(img.shape)
img_nor = plt.imshow(img)
plt.show()

"""Mostramos una imagende incendio"""

plt.figure(figsize=(8,6))
img_1 = imread('../content/train/wildfire/-57.11902,51.47242.jpg')
img_pne = plt.imshow(img_1)
plt.show()
print(img_1, "\n")
print(img_1.shape)

"""**La imagen es monocromática: Si la imagen es monocromática en lugar de estar en escala de grises, el mapa de colores gray tampoco producirá un cambio visible.**"""

fig, axar = plt.subplots(2,1, figsize=(12,10))
img  = plt.imread('../content/train/nowildfire/-113.917243,51.101323.jpg')
mg_gray = color.rgb2gray(plt.imread('../content/train/nowildfire/-113.917243,51.101323.jpg'))
axar[0].imshow(img)
axar[0].set_title("Orginal Image")
axar[1].imshow(mg_gray, cmap='gray')
axar[1].set_title("Gray Scale Image")
plt.show()

def sides(image):
    fig, im = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))
    im[0].imshow(image)
    im[0].set_title('Original Image', fontsize=24)
    im[1].imshow(cv2.flip(image, 0))
    im[1].set_title('Vertical Flip', fontsize=24)
    im[2].imshow(cv2.flip(image, 1))
    im[2].set_title('Horizontal Flip', fontsize=24)
    plt.show()
sides(img_1)

def sides(image):
    fig, im = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))

    # Mostrar la imagen original en el primer subplot
    im[0].imshow(image, cmap='gray')
    im[0].set_title('Original Image', fontsize=24)

    # Mostrar el volteo vertical en el segundo subplot
    im[1].imshow(cv2.flip(image, 0), cmap='gray')
    im[1].set_title('Vertical Flip', fontsize=24)

    # Mostrar el volteo horizontal en el tercer subplot
    im[2].imshow(cv2.flip(image, 1), cmap='gray')
    im[2].set_title('Horizontal Flip', fontsize=24)

    plt.show()

# Llamar a la función con la imagen en escala de grises
sides(img_gray)

in_put = io.imread('../content/train/wildfire/-57.8088,51.44634.jpg')
plt.imshow(in_put)
plt.show()

rescaled = rescale(in_put, 1.0/4.0, anti_aliasing=True)
plt.imshow(rescaled)
plt.show()

print(in_put.shape)
print(rescaled.shape)

resized_img = resize(rescaled, (200, 200))
plt.imshow(resized_img)
plt.show()

down_s_l = downscale_local_mean(img, (4,3,3))
plt.imshow(down_s_l)
plt.show()

edge_rober = roberts(img_1[:, :, 0])  # Aplicar operador de detección de bordes a cada canal por separado
edge_sobel = sobel(img_1[:, :, 1])
edge_scharr = scharr(img_1[:, :, 2])
edge_prewitt = prewitt(img_1[:, :, 0])

def sides(image, edge_rober, edge_sobel, edge_scharr, edge_prewitt):
    fig, im = plt.subplots(nrows=1, ncols=5, figsize=(50, 30))

    # Mostrar la imagen original
    im[0].imshow(image)
    im[0].set_title('Original Image', fontsize=24)

    # Mostrar los bordes detectados por Roberts
    im[1].imshow(edge_rober)
    im[1].set_title('Edge Rober', fontsize=24)

    # Mostrar los bordes detectados por Sobel
    im[2].imshow(edge_sobel)
    im[2].set_title('Edge Sobel', fontsize=24)

    # Mostrar los bordes detectados por Scharr
    im[3].imshow(edge_scharr)
    im[3].set_title('Edge Scharr', fontsize=24)

    # Mostrar los bordes detectados por Prewitt
    im[4].imshow(edge_prewitt)
    im[4].set_title('Edge Prewitt', fontsize=24)

    # Desactivar los ejes en todas las subfiguras
    for a in im:
        a.axis("off")

    plt.tight_layout()
    plt.show()

# Llamar a la función con los bordes detectados y la imagen original
sides(img_1, edge_rober, edge_sobel, edge_scharr, edge_prewitt)

# Aplicar el algoritmo Canny a cada canal por separado
img_canny = np.zeros_like(img, dtype=bool)
for i in range(img.shape[2]):
    img_canny[:, :, i] = canny(img[:, :, i], sigma=0)

# Convertir la matriz booleana a un tipo de datos compatible (por ejemplo, uint8)
img_canny_uint8 = img_canny.astype(np.uint8) * 255  # Escalar a [0, 255]

# Mostrar la imagen tridimensional después de aplicar Canny
plt.figure(figsize=(6, 5))
plt.imshow(img_canny_uint8)
plt.show()

# Inicializar una matriz para almacenar la entropía
ent_img = np.zeros_like(in_put[:, :, 0], dtype=float)

# Calcular la entropía para cada canal por separado y combinar los resultados
for i in range(in_put.shape[2]):
    ent_img += entropy(in_put[:, :, i], disk(3))

# Normalizar los valores de entropía para que estén en el rango [0, 1]
ent_img /= ent_img.max()

# Mostrar la imagen de entropía
plt.imshow(ent_img, cmap="gray")
plt.show()

def camp(image):


    fig, im = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))
    im[0].imshow(image, cmap="gray")
    im[0].set_title('Original Image', fontsize=24)



    gussian_img = ndimage.gaussian_filter(image, sigma=3)
    im[1].imshow(gussian_img, cmap="gray")
    im[1].set_title("Gaussian Filter", fontsize=24)

    plt.show()
camp(in_put)

train = get_training_data('../content/train')
test = get_training_data('../content/test')
valid = get_training_data('../content/valid')